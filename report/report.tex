\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}	% Para caracteres en espa√±ol
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{fullpage}
\usepackage{setspace}
\usepackage[margin=3cm]{geometry}
\usepackage[hidelinks]{hyperref}

\setlength{\fboxsep}{0.05\textwidth}

\newcommand{\commentEq}[1]{%
  \text{\phantom{(#1)}} \tag{#1}
}
\geometry{margin=1in, headsep=0.25in}

\begin{document}
\setcounter{section}{0}
\thispagestyle{empty}

\noindent\fbox{\begin{minipage}{0.9\textwidth}
  \begin{center}
    \section*{CS 7140: Advanced Machine Learning}
	\subsection*{Project Report:  Weight Uncertainty in Neural Networks}
  \end{center}
  
  \noindent\textbf{Instructor}
  \smallskip
  
  Jan-Willem van de Meent (\url{j.vandemeent@northeastern.edu})\\
  
  \noindent\textbf{Students}
  \smallskip

  Colin Kohler (\url{kohler.c@husky.neu.edu})\\
  Andrea Baisero (\url{baisero.a@husky.neu.edu})
\end{minipage}}
\bigskip

\newcommand\RR{{\mathbb{R}}}

\section{Introduction}
A well known problem with artificial netural networks is their tendency to 
overfit their training data. This overfitting results in a extremely low 
error on the training data and a large error on the test data. More concretely,
we can state that the network has become overly confident about the amount of
uncertainty in the training data and therfor makes predictions on the test
data which are unrealisticly optimistic. There are two main techiniques used
to combat this problem: eary stopping and regularization. 

Early stopping is the most naive method to prevent overfitting and simply 
involves stopping the network's training once the test error has begun to
increase. The second technique, regularization, involves modifying the loss 
function by adding a penalty term. Through the addition of this penalty, the
network is forced to learn a more general model of the data thereby avoiding
overfitting. In this report we will implement and test a regularization 
technique known as \textit{Bayes by Backprop}\cite{} which utilizes 
variational Bayesian learning to introduce uncertainty in the weight of the 
neural network.
\subsection{Background}

\subsubsection{Artificial Neural Networks}
\subsubsection{Black Box Variational Inference}

\section{Bayes by Backprop}

\section{Experiments}

\subsection{Classification}
\paragraph{Data --- MNIST}
\paragraph{Results}

\subsection{Regression}
\paragraph{Data --- Synthetic Data}
\paragraph{Results}

\subsection{Contextual Bandits}

Contextual Bandits (CB) is a standard problem domain type from the field of
Reinforcement Learning (RL), and can be interpreted as either an extension of
Multi-Armed Bandits (MAB), or a precursor to full-blown Markov Decision
Processes (MDP).

% The agent receives a i.d.d.\ contexts sampled from an unknown distribution
% $P(x)$.

% In a CB problem, the agent receives a \emph{context} $x\in\RR^d$ sampled from
% an unknown distribution $P(x)$.

% The general CB problem is as follows:  The CB agent receives a \emph{context}
% $x\in\RR^d$;  This process is repeated either indefinitely or for a fixed
% number of time steps (the horizon);  the objective is that of maximizing the
% long-term average of all received rewards.

% At each time step, the CB agent receives a \emph{context} $x\in\RR^d$

% The CB problem consists in the usual

The methods for solving CB problems can be roughly split into three
categories:
%
\begin{itemize}
  %
  \item Non-Bayesian
  %
  \item Bayesian (Optimal)
  %
  \item Bayesian (Heuristic)
  %
\end{itemize}

\paragraph{Data --- Mushroom Domain}

\paragraph{Results}

\section{Conclusions}

\end{document}
